### Kafka properties ####################################
# all properties starting with this prefix - will be added to KafkaProperties object
# with the property name = original property name minus the prefix
kafka.consumer.property.prefix=consumer.kafka.property.
# Kafka Brokers host:port list: <host1>:<port1>,â€¦,<hostN>:<portN>
consumer.kafka.property.bootstrap.servers=localhost:9092

# Kafka Consumer group name prefix - 
# each job will have a clientId = kafka.consumer.group.name + "_" + partitionNumber
consumer.kafka.property.group.id=kafkabatch-consumer

# kafka session timeout in ms - is kafka broker does not get a heartbeat from a consumer during this interval -
# consumer is marked as 'dead' and re-balancing is kicking off
# default: 30s x 1000 = 30000 ms
consumer.kafka.property.session.timeout.ms=30000

# Max number of bytes to fetch in one poll request PER partition
# default: 1M = 1048576
consumer.kafka.property.max.partition.fetch.bytes=1048576
### End of Kafka properties ####################################

### Application properties ####################################

# application instance name:
# used as a common name prefix of all consumer threads
application.id=app1

# Kafka Topic from which the message has to be processed
kafka.consumer.source.topic=my_log_topic

#Number of consumer threads
kafka.consumer.pool.count=5

# time in ms to wait for new messages to arrive when calling poll() on Kafka brokers , if there are no messages right away
# WARNING: make sure this value is not higher than session.timeout.ms !!!
# default: 10 sec = 10 x 1000 = 10000 ms
kafka.consumer.poll.interval.ms=10000

# number of time poll records will be attempted to be re-processed in the event of a recoverable exception 
# from the IBatchMessageProcessor.beforeCommitCallBack() method 
kafka.consumer.poll.retry.limit=5

# time delay in ms before retries of the poll records in the event of a recoverable exception
# from the IBatchProcessor.completePoll() method
kafka.consumer.poll.retry.delay.interval.ms=1000
# in the case when the max limit of recoverable exceptions was reached:
# if set to TRUE - ignore the exception and continue processing the next poll()
# if set to FALSE - throw ConsumerUnrecoverableException and shutdown the Consumer
kafka.consumer.ignore.overlimit.recoverable.errors=false
